%1
%%% No free lunch theorem %%%
@book{James,
series = {Springer Texts in Statistics, 103},
abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, and more. Color graphics and real-world examples are used to illustrate the methods presented. Since the goal of this textbook is to facilitate the use of these statistical learning techniques by practitioners in science, industry, and other fields, each chapter contains a tutorial on implementing the analyses and methods presented in R, an extremely popular open source statistical software platform. Two of the authors co-wrote The Elements of Statistical Learning (Hastie, Tibshirani and Friedman, 2nd edition 2009), a popular reference book for statistics and machine learning researchers. An Introduction to Statistical Learning covers many of the same topics, but at a level accessible to a much broader audience. This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.},
isbn = {9781461471387},
year = {2013},
title = {An Introduction to Statistical Learning with Applications in R},
language = {eng},
author = {Gareth, James and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
keywords = {Statistics; Artificial intelligence},
}

%2
@article{Bayindir,
author = {Bayindir, Levent},
title = {{A review of swarm robotics tasks}},
doi = {10.1016/j.neucom.2015.05.116},
isbn = {0925-2312},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Cooperation,Distributed task,Swarm robotics},
pages = {292--321},
pmid = {26916440},
year = {2015}
}


%3
@article{Vehlken,
author = {Sebastian, Vehlken},
journal = {Next Generation Building 3},
keywords = {abm,agent-based modeling,architectural design,si,swarm intelligence,swarm robotics},
pages = {487--490},
title = {{Swarm Robotics , or ' The Smartness of a bunch of cheap dumb things '}},
volume = {1},
year = {2016}
}


%4
@inproceedings{Mohan,
  title={An extensive review of research in swarm robotics},
  author={Mohan, Yogeswaran and Ponnambalam, SG},
  booktitle={2009 World Congress on Nature \& Biologically Inspired Computing (NaBIC)},
  organization={IEEE},
  pages={140--145},
  year={2009},
}


%5
@misc{TEDx,
author = {{TEDx}},
title = {{Swarm robotics -- from local rules to global behaviors | Magnus Egerstedt | TEDxEmory}},
url = {https://www.youtube.com/watch?v=ULKyXnQ9xWA},
urldate = {2019-02-18},
year = {2014}
}

%6
@article{Webb,
issn = {0954-0091},
journal = {Connection Science},
pages = {163--164},
volume = {14},
number = {2},
year = {2002},
title = {Swarm Intelligence: From Natural to Artificial Systems},
language = {eng},
author = {Webb, Barbara},
keywords = {Computer Science;},
}


%7
@article{Couceiro2014,
title = {Benchmark of swarm robotics distributed techniques in a search task},
issn = {0921-8890},
journal = {Robotics and Autonomous Systems},
pages = {200--213},
volume = {62},
publisher = {Elsevier B.V.},
number = {2},
year = {2014},
author = {Couceiro, Micael S. and Vargas, Patricia A. and Rocha, Rui P. and Ferreira, Nuno M.F.},
keywords = {Swarm Robotics ; Search Tasks ; Benchmark ; Performance Analysis},
}


%8
@misc{Nedjah,
author = {Nedjah, Nadia and de {Macedo Mourelle}, Luiza},
title = {{Distributed learning algorithms for swarm robotics}},
url = {http://dx.doi.org/10.1016/j.neucom.2015.06.085},
year = {2015}
}


%9
@misc{TEDx2016,
title = {{Taming the swarm - Collective Artificial Intelligence | Radhika Nagpal | TEDxBermuda - YouTube}},
author = {TEDx2016},
url = {https://www.youtube.com/watch?v=LHgVR0lzFJc},
urldate = {2019-03-16}
}

%10
@article{SHoR,
author = {Siciliano, Bruno and Khatib, Oussama},
publisher = {Springer International Publishing},
isbn = {9783319325507},
year = {2016},
title = {Springer Handbook of Robotics, 2nd Edition},
edition = {2nd Edition},
}


%11
@article{Parker,
issn = {1888-0258},
abstract = {This article overviews the concepts of distributed intelligence, outlining the motivations for studying this field of research. First, common systems of distributed intelligence are classified based upon the types of interactions exhibited, since the type of interaction has relevance to the solution paradigm to be used. We outline three common paradigms for distributed intelligence — the bioinspired paradigm, the organizational and social paradigm, and the knowledge-based, ontological paradigm — and give examples of how these paradigms can be used in multi-robot systems. We then look at a common problem in multi-robot systems — that of task allocation — and show how the solution approach to this problem is very different depending upon the paradigm chosen for abstracting the problem. Our conclusion is that the paradigms are not interchangeable, but rather the selection of the appropriate paradigm is dependent upon the specific constraints and requirements of the application of interest. Further work is needed to provide guidance to the system designer on selecting the proper abstraction, or paradigm, for a given problem.},
journal = {JoPha: Journal of Physical Agents},
pages = {5--14},
volume = {2},
number = {1},
year = {2008},
title = {Distributed intelligence: overview of the field and its application in multi-robot systems},
language = {eng},
author = {Parker, Lynne E.},
keywords = {Distributed Intelligence ; Multi - Robot Systems ; Multi - Agent Systems ; Task Allocation},
url = {https://dialnet.unirioja.es/servlet/oaiart?codigo=5645537},
}


%12
@article{Bakhshipour,
issn = {1568-4946},
journal = {Applied Soft Computing},
pages = {708--726},
volume = {57},
publisher = {Elsevier B.V.},
year = {2017},
title = {Swarm robotics search and rescue: A novel artificial intelligence-inspired optimization approach},
language = {eng},
author = {Bakhshipour, M. and Jabbari Ghadi, M. and Namdari, F.},
keywords = {Swarm Robotics ; Evolutionary Algorithms ; Nonlinear Optimization},
}

%13
@article{Brambilla,
author = {Brambilla, Manuele and Ferrante, Eliseo and Birattari, Mauro and Dorigo, Marco},
doi = {10.1007/s11721-012-0075-2},
isbn = {1935-3812},
issn = {19353812},
journal = {Swarm Intelligence},
keywords = {Review,Swarm engineering,Swarm robotics},
number = {1},
pages = {1--41},
title = {{Swarm robotics: A review from the swarm engineering perspective}},
volume = {7},
year = {2013}
}


%14
@incollection{Couceiro,
title = {An Overview of Swarm Robotics for Search and Rescue Applications},
abstract = {The area of research presented in this chapter focuses on swarm robotics, which is a particular domain of multi-robot systems (MRS) that embodies the mechanisms of swarm intelligence into robotics. More specifically, this chapter overviews the applicability of swarm robotic solutions into search and rescue (SaR) real-world missions. In this chapter, SaR operations are considered as a vital target application wherein swarm robotics can be applied due to their inherent level of complexity. Such operations often occur in highly dynamic and large scenarios, with harsh and faulty conditions, that pose several problems to traditional MRS applicability. This chapter focuses on these problems highlighting the challenges that cannot be handled appropriately by simple adaptation of traditional algorithms, planning, control and decision-making techniques.},
pages = {1522--1561},
booktitle = {Artificial Intelligence},
isbn = {9781522517603},
year = {2017},
author = {Couceiro, Micael},
}

%15
@book{Mitchell,
series = {McGraw-Hill series in computer science},
publisher = {McGraw-Hill},
isbn = {9780070428072},
year = {1997},
title = {Machine Learning},
language = {eng},
address = {New York},
author = {Mitchell, Tom M. (Tom Michael)},
keywords = {Machine learning; Computer algorithms},
lccn = {97007692},
}

%16
@book{Alpaydin,
series = {Adaptive computation and machine learning},
abstract = {Machine learning is rapidly becoming a skill that computer science students must master before graduation. The third edition of this title reflects this shift, with added support for beginners, including selected solutions for exercises and additional example data sets (with code available online). Other substantial changes include discussions of outlier detection; ranking algorithms for perceptrons and support vector machines; matrix decomposition and spectral methods; distance estimation; new kernel algorithms; deep learning in multilayered perceptrons; and the nonparametric approach to Bayesian methods. All learning algorithms are explained so that students can easily move from the equations in the book to a computer program. The book can be used by both advanced undergraduates and graduate students. It will also be of interest to professionals who are concerned with the application of machine learning methods. --},
publisher = {MIT Press},
isbn = {9780262325745},
year = {2014},
title = {Introduction to machine learning},
edition = {Third edition..},
language = {eng},
address = {Cambridge, Mass.},
author = {Alpaydin, Ethem},
keywords = {Machine learning},
}

%17
@book{Mohammed,
abstract = {Explaining the concepts of machine learning algorithms, this practical book describes the application areas of each algorithm discussed, and uses simple, practical examples to help readers understand each algorithm. --},
isbn = {9781498705387},
year = {2017},
title = {Machine learning : algorithms and applications},
language = {eng},
author = {Mohammed, Mohssen},
keywords = {Machine learning; Computer algorithms},
}

%18
@book{Corea,
series = {Studies in Big Data, 50},
isbn = {9783030044688},
year = {2019},
title = {An Introduction to Data Everything You Need to Know About AI, Big Data and Data Science},
language = {eng},
author = {Corea, Francesco},
}

%19
@inproceedings{Iima2,
pages = {2298-2303},
organization = {IEEE},
booktitle = {2013 IEEE International Conference on Systems, Man, and Cybernetics},
year = {2013},
title = {Swarm Reinforcement Learning Method for a Multi-robot Formation Problem},
author = {Iima, Hitoshi and Kuroe, Yasuaki},
}
%20

@book{Hastie,
series = {Springer Series in Statistics},
abstract = {During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for ``wide'' data (p bigger than n), including multiple testing and false discovery rates. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting.},
isbn = {9780387848587},
year = {2009},
title = {The Elements of Statistical Learning Data Mining, Inference, and Prediction},
edition = {Second Edition..},
language = {eng},
author = {Hastie, Trevor},
keywords = {Computer science; Data mining; Artificial intelligence; Bioinformatics; Computational biology; Probabilities; Statistics},
}

%21
@misc{CHF,
abstract = {Watch as a throng of tiny, self-organizing machines—flashing lights on, speakers playing vintage video game music—search, cluster, and disperse with a single command. We owe much of this groundbreaking technology—known as "swarm robotics"—to visionary engineer James McLurkin, named one of the country's top five robot designers by Time magazine. His machines perform striking organizational and teamwork tasks in a method with origins in the behavior of ants and bees, and with real-world application and stakes: his swarm can clear minefields, execute complex missions on Mars, and search the aftermath of natural disasters for survivors. Learn more from McLurkin and witness his mechanical colony in action.

This program is generously underwritten by the Lohengrin Foundation.},
author = {{Chicago Humanities Festival}},
title = {{Swarm Robotics: Invasion of the Robot Ants - YouTube}},
url = {https://www.youtube.com/watch?v=BeUT{\_}AL6t4A{\&}t=418s},
urldate = {2019-03-04},
year = {2013}
}

%22
@book{Welling,
publisher = {University of California Irvine},
year = {2011},
title = {A First Encounter with Machine Learning},
language = {eng},
address = {Irvine, CA 92697, USA},
author = {Welling, Max},
}

@book{Dorigo,
publisher = {MIT Press},
isbn = {0262042193},
year = {2004},
title = {Ant colony optimization},
language = {eng},
address = {Cambridge, Mass.},
author = {Dorigo, Marco},
keywords = {Ants -- Behavior -- Mathematical models; Mathematical optimization},
}



%23
@misc{Sundblad,
author = {Sundblad, Willem},
booktitle = {Forbes},
title = {{Data Is The Foundation For Artificial Intelligence And Machine Learning}},
url = {https://www.forbes.com/sites/willemsundbladeurope/2018/10/18/data-is-the-foundation-for-artificial-intelligence-and-machine-learning/?fbclid=IwAR1i3wt-4zSgMEmrsS32071KhRD-6thBftdtZdj7b1KmVN{\_}Sry21Mr2BWOY{\#}138a98db51b4},
urldate = {2019-03-25},
year = {2019}
}
%24
@misc{Kumar2019,
author = {{Vijay Kumar}},
title = {{Kumar Robotics}},
url = {https://www.kumarrobotics.org/research/},
urldate = {2019-03-24},
year = {2019}
}

%25
@misc{TED,
author = {TED},
title = {{The Future of Flying Robots | Vijay Kumar | TED Talks - YouTube}},
url = {https://www.youtube.com/watch?v=ge3--1hOm1s},
urldate = {2019-02-25},
year = {2015}
}

%26

@misc{AMNH,
author = {{American Museum of Natural History}},
title = {{Swarms of Aerial Robots - AMNH SciCafe - YouTube}},
url = {https://www.youtube.com/watch?v=mUeyfLIGtLQ{\&}t=636s},
urldate = {2019-02-25},
year = {2016}
}

%27
@article{Kumar2018,
abstract = {We present a novel fruit counting pipeline that combines deep segmentation, frame to frame tracking, and 3D localization to accurately count visible fruits across a sequence of images. Our pipeline works on image streams from a monocular camera, both in natural light, as well as with controlled illumination at night. We first train a Fully Convolutional Network (FCN) and segment video frame images into fruit and non-fruit pixels. We then track fruits across frames using the Hungarian Algorithm where the objective cost is determined from a Kalman Filter corrected Kanade-Lucas-Tomasi (KLT) Tracker. In order to correct the estimated count from tracking process, we combine tracking results with a Structure from Motion (SfM) algorithm to calculate relative 3D locations and size estimates to reject outliers and double counted fruit tracks. We evaluate our algorithm by comparing with ground-truth human-annotated visual counts. Our results demonstrate that our pipeline is able to accurately and reliably count fruits across image sequences, and the correction step can significantly improve the counting accuracy and robustness. Although discussed in the context of fruit counting, our work can extend to detection, tracking, and counting of a variety of other stationary features of interest such as leaf-spots, wilt, and blossom.},
year = {2018},
title = {Robust Fruit Counting: Combining Deep Learning, Tracking, and Structure from Motion},
author = {Liu, Xu and Chen, Steven W. and Aditya, Shreyas and Sivakumar, Nivedha and Dcunha, Sandeep and Qu, Chao and Taylor, Camillo J. and Das, Jnaneshwar and Kumar, Vijay},
keywords = {Computer Science - Computer Vision And Pattern Recognition},
}

%28
@inproceedings{Iima,
pages = {3026-3033},
organization = {IEEE},
booktitle = {2015 IEEE Congress on Evolutionary Computation (CEC)},
year = {2015},
title = {Swarm reinforcement learning methods improving certainty of learning for a multi-robot formation problem},
language = {eng},
author = {Iima, Hitoshi and Kuroe, Yasuaki},
}

%29
@article{Zheng2017,
abstract = {We introduce MAgent, a platform to support research and development of many-agent reinforcement learning. Unlike previous research platforms on single or multi-agent reinforcement learning, MAgent focuses on supporting the tasks and the applications that require hundreds to millions of agents. Within the interactions among a population of agents, it enables not only the study of learning algorithms for agents' optimal polices, but more importantly, the observation and understanding of individual agent's behaviors and social phenomena emerging from the AI society, including communication languages, leaderships, altruism. MAgent is highly scalable and can host up to one million agents on a single GPU server. MAgent also provides flexible configurations for AI researchers to design their customized environments and agents. In this demo, we present three environments designed on MAgent and show emerged collective intelligence by learning from scratch.},
year = {2017},
title = {MAgent: A Many-Agent Reinforcement Learning Platform for Artificial Collective Intelligence},
author = {Zheng, Lianmin and Yang, Jiacheng and Cai, Han and Zhang, Weinan and Wang, Jun and Yu, Yong},
keywords = {Computer Science - Learning ; Computer Science - Artificial Intelligence ; Computer Science - Multiagent Systems},
}

%30
@article{Max,
abstract = {Recently, deep reinforcement learning (RL) methods have been applied successfully to multi-agent scenarios. Typically, these methods rely on a concatenation of agent states to represent the information content required for decentralized decision making. However, concatenation scales poorly to swarm systems with a large number of homogeneous agents as it does not exploit the fundamental properties inherent to these systems: (i) the agents in the swarm are interchangeable and (ii) the exact number of agents in the swarm is irrelevant. Therefore, we propose a new state representation for deep multi-agent RL based on mean embeddings of distributions. We treat the agents as samples of a distribution and use the empirical mean embedding as input for a decentralized policy. We define different feature spaces of the mean embedding using histograms, radial basis functions and a neural network learned end-to-end. We evaluate the representation on two well known problems from the swarm literature (rendezvous and pursuit evasion), in a globally and locally observable setup. For the local setup we furthermore introduce simple communication protocols. Of all approaches, the mean embedding representation using neural network features enables the richest information exchange between neighboring agents facilitating the development of more complex collective strategies.},
year = {2018},
title = {Deep Reinforcement Learning for Swarm Systems},
author = {Huttenrauch, Maximilian and SoSic, Adrian and Neumann, Gerhard},
keywords = {Computer Science - Multiagent Systems ; Computer Science - Artificial Intelligence ; Computer Science - Machine Learning ; Computer Science - Systems And Control ; Statistics - Machine Learning},
}

%31
@article{Lowe,
abstract = {We explore deep reinforcement learning methods for multi-agent domains. We begin by analyzing the difficulty of traditional algorithms in the multi-agent case: Q-learning is challenged by an inherent non-stationarity of the environment, while policy gradient suffers from a variance that increases as the number of agents grows. We then present an adaptation of actor-critic methods that considers action policies of other agents and is able to successfully learn policies that require complex multi-agent coordination. Additionally, we introduce a training regimen utilizing an ensemble of policies for each agent that leads to more robust multi-agent policies. We show the strength of our approach compared to existing methods in cooperative as well as competitive scenarios, where agent populations are able to discover various physical and informational coordination strategies.},
year = {2017},
title = {Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
author = {Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},
keywords = {Computer Science - Learning ; Computer Science - Artificial Intelligence ; Computer Science - Neural And Evolutionary Computing},
}

%32
@misc{Max2,
author = {Huttenrauch, Maximillian},
title = {{Arxiv: New paper on "Deep Reinforcement Learning for Swarm Systems" plus videos and code – Computational Learning for Autonomous Systems}},
url = {http://computational-learning.net/deep\_rl\_for\_swarms\#respond},
urldate = {2019-03-30},
year = {2018},
publisher = {Lincoln Center for Autonomous Systems}
}

%33
@article{Amigo,
issn = {0302-9743},
journal = {RoboCup 2012: Robot Soccer World Cup XVI},
pages = {20--35},
isbn = {9783642392498},
year = {2013},
title = {RoboCup 2012 Rescue Simulation Winners},
language = {eng},
author = {Amigoni, F. and Visser, A. and Tsushima, M. and Chen, X. and Stone, P. and Sucar, L.E. and van der Zant, T.},
}


%34
@misc{RoboCup,
author = {{RoboCup Federation}},
title = {{RoboCup Federation official website}},
url = {https://www.robocup.org/},
urldate = {2019-04-02}
}

%35
@article{Penders,
issn = {0169-1864},
journal = {Advanced Robotics},
pages = {93--117},
volume = {25},
number = {1-2},
year = {2011},
title = {A Robot Swarm Assisting a Human Fire-Fighter},
language = {eng},
author = {Penders, Jacques and Alboul, Lyuba and Witkowski, Ulf and Naghsh, Amir and Saez-Pons, Joan and Herbrechtsmeier, Stefan and El-Habbal, Mohamed},
}


%36
@incollection{Murphy,
abstract = {<p> In order to summarize the status of rescue robotics, this chapter will cover the basic characteristics of disasters and their impact on robotic design, describe the robots actually used in disasters to date, promising robot designs (e.g., snakes, legged locomotion) and concepts (e.g., robot teams or swarms, sensor networks), methods of evaluation in benchmarks for rescue robotics, and conclude with a discussion of the fundamental problems and open issues facing rescue robotics, and their evolution from an interesting idea to widespread adoption. The Chapter will concentrate on the rescue phase, not recovery, with the understanding that capabilities for rescue can be applied to, and extended for, the recovery phase. The use of robots in the prevention and preparedness phases of disaster management are outside the scope of this chapter. </p>},
pages = {1151--1173},
publisher = {Springer Berlin Heidelberg},
booktitle = {Springer Handbook of Robotics},
isbn = {9783540239574},
year = {2008},
title = {Search and Rescue Robotics},
language = {eng},
address = {Berlin, Heidelberg},
author = {Murphy, Robin R and Tadokoro, Satoshi and Nardi, Daniele and Jacoff, Adam and Fiorini, Paolo and Choset, Howie and Erkmen, Aydan M},
keywords = {Engineering ; Control, Robotics, Mechatronics ; Artificial Intelligence (Incl. Robotics) ; Computer Applications ; Computational Intelligence ; Electrical Engineering ; Engineering},
}



%37
@article{Lomonaco,
abstract = {In recent years, a rising numbers of people arrived in the European Union, traveling across the Mediterranean Sea or overland through Southeast Europe in what has been later named as the European migrant crisis. In the last 5 years, more than 16 thousands people have lost their lives in the Mediterranean sea during the crossing. The United Nations Secretary General Strategy on New Technologies is supporting the use of Artificial Intelligence (AI) and Robotics to accelerate the achievement of the 2030 Sustainable Development Agenda, which includes safe and regular migration processes among the others. In the same spirit, the central idea of this project aims at using AI technology for Search And Rescue (SAR) operations at sea. In particular, we propose an autonomous fleet of self-organizing intelligent drones that would enable the coverage of a broader area, speeding-up the search processes and finally increasing the efficiency and effectiveness of migrants rescue operations.},
year = {2018},
title = {Intelligent Drone Swarm for Search and Rescue Operations at Sea},
author = {Lomonaco, Vincenzo and Trotta, Angelo and Ziosi, Marta and Ávila, Juan de Dios Yáñez and Díaz-Rodríguez, Natalia},
keywords = {Computer Science - Computers And Society ; Computer Science - Artificial Intelligence},
}


%38
@article{Wilson,
issn = {2054-5703},
journal = {Royal Society open science},
pages = {180409--180409},
volume = {5},
number = {10},
year = {2018},
title = {Multi-robot replication of ant collective towing behaviours.},
language = {eng},
author = {Wilson, Sean and Buffin, Aurélie and Pratt, Stephen C and Berman, Spring},
keywords = {Ants ; Decentralized Coordination ; Heterogeneous Teams ; Reinforcement Learning ; Self-Organization ; Swarm Robotics},
url = {http://search.proquest.com/docview/2138046497/},
}

%39
@incollection{Han,
series = {Lecture Notes in Computer Science},
abstract = {<p>Traditional extreme learning machine (ELM) may require high number of hidden neurons and lead to ill-condition problem due to the random determination of the input weights and hidden biases. In this paper, we use a modified particle swarm optimization (PSO) algorithm to select the input weights and hidden biases of single-hidden-layer feedforward neural networks (SLFN) and Moore–Penrose (MP) generalized inverse to analytically determine the output weights. The modified PSO optimizes the input weights and hidden biases according to not only the root mean squared error on validation set but also the norm of the output weights. The proposed algorithm has better generalization performance than other ELMs and its conditioning is also improved.</p>},
pages = {699--704},
volume = {6840},
publisher = {Springer Berlin Heidelberg},
booktitle = {Bio-Inspired Computing and Applications: 7th International Conference on Intelligent Computing, ICIC 2011, Zhengzhou,China, August 11-14. 2011, Revised Selected Papers},
isbn = {9783642245527},
year = {2012},
title = {An Improved Extreme Learning Machine Based on Particle Swarm Optimization},
language = {eng},
address = {Berlin, Heidelberg},
author = {Han, Fei and Yao, Hai-Fen and Ling, Qing-Hua},
keywords = {Computer Science ; Artificial Intelligence (Incl. Robotics) ; Pattern Recognition ; Information Systems Applications (Incl. Internet) ; Image Processing and Computer Vision ; Computation By Abstract Devices ; User Interfaces and Human Computer Interaction ; Engineering ; Computer Science},
}

%40
@inproceedings{Zhiguo2,
pages = {952-957},
organization = {IEEE},
booktitle = {2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
isbn = {9781479927449},
year = {2013},
title = {Adaptive reinforcement Q-Learning algorithm for swarm-robot system using pheromone mechanism},
language = {eng},
author = {Zhiguo, Shi and Jun, Tu and Yuankai, Li and Zeying, Wang},
}





%41
@inproceedings{Breck, 
author={E. {Breck} and S. {Cai} and E. {Nielsen} and M. {Salib} and D. {Sculley}}, 
booktitle={2017 IEEE International Conference on Big Data (Big Data)}, 
title={The ML test score: A rubric for ML production readiness and technical debt reduction}, 
year={2017}, 
volume={}, 
number={}, 
pages={1123-1132}, 
keywords={learning (artificial intelligence);program testing;software reliability;system monitoring;ML test score;ML production readiness;technical debt reduction;ML system;actual prediction behavior;production ML systems;ML technical debt;production-level machine learning systems;system testing;system monitoring;road-map;Testing;Production;Data models;Measurement;Training;Reliability;Monitoring;Machine Learning;Testing;Monitoring;Reliability;Best Practices;Technical Debt}, 
doi={10.1109/BigData.2017.8258038}, 
ISSN={}, 
month={Dec},}

%%%%%%%%%%%%%%%
@inproceedings{Kennedy,
pages = {1942-1948 vol.4},
organization = {IEEE},
booktitle = {Proceedings of ICNN'95 - International Conference on Neural Networks},
year = {1995},
title = {Particle swarm optimization},
language = {eng},
author = {Kennedy, J and Eberhart, R},
}

@book{PSO,
publisher = {IGI Global (701 E. Chocolate Avenue, Hershey, Pennsylvania, 17033, USA)},
isbn = {9781615206674},
year = {2010},
title = {Particle swarm optimization and intelligence advances and applications},
language = {eng},
address = {Hershey, Pa.},
author = {Parsopoulos, Konstantinos E.},
}





%%%%%%%%%%%%%%%


%42

@article{Zeng,
issn = {09252312},
abstract = {In this paper, a hybrid learning approach, which combines the extreme learning machine (ELM) with a new switching delayed PSO (SDPSO) algorithm, is proposed for the problem of the short-term load forecasting (STLF). In particular, the input weights and biases of ELM are optimized by a new developed SDPSO algorithm, where the delayed information of locally best particle and globally best particle are exploited to update the velocity of particle. By testing the proposed SDPSO-ELM in a comprehensive manner on a tanh function, this approach obtain better generalization performance and can also avoid adding unnecessary hidden nodes and overtraining problems. Moreover, it has shown outstanding performance than other state-of-the-art ELMs. Finally, the proposed SDPSO-ELM algorithm is successfully applied to the STLF of power system. Experiment results demonstrate that the proposed learning algorithm can get better forecasting results in comparison with the radial basis function neural network (RBFNN) algorithm.},
journal = {Neurocomputing},
pages = {175--182},
volume = {240},
publisher = {Elsevier B.V.},
year = {2017},
title = {A switching delayed PSO optimized extreme learning machine for short-term load forecasting},
copyright = {Copyright 2017 Elsevier B.V., All rights reserved.},
author = {Zeng, N. and Zhang, H. and Liu, W. and Liang, J. and Alsaadi, F.E.},
keywords = {Extreme Learning Machine ; Neural Network ; Short-Term Load Forecasting ; Switching Delayed Particle Swarm Optimization (Sdpso) ; Time-Delay},
}


%43
@book{Dorigo,
publisher = {MIT Press},
isbn = {0262042193},
year = {2004},
title = {Ant colony optimization},
language = {eng},
address = {Cambridge, Mass.},
author = {Dorigo, Marco},
keywords = {Ants -- Behavior -- Mathematical models; Mathematical optimization},
}


%44
@inproceedings{Zhiguo,
issn = {2161-2927},
pages = {6033-6038},
organization = {TCCT, CAA},
booktitle = {Proceedings of the 32nd Chinese Control Conference},
year = {2013},
title = {The improved Q-Learning algorithm based on pheromone mechanism for swarm robot system},
author = {Zhiguo Shi and Jun Tu and Qiao Zhang and Xiaomeng Zhang and Junming Wei},
}
%45 extra
@book{Henrich,
series = {Evolution and cognition},
publisher = {Oxford University Press},
isbn = {9780195300680},
year = {2007},
title = {Why humans cooperate : a cultural and evolutionary explanation},
language = {eng},
address = {Oxford, Toronto},
author = {Henrich, Natalie},
keywords = {Interpersonal relations -- Case studies; Chaldean Catholics -- Michigan -- Detroit Region},
lccn = {2006048326},
}




% Extras for the table


@inproceedings{Mohan2,
pages = {15--21},
publisher = {IEEE},
booktitle = {2013 IEEE Symposium on Swarm Intelligence (SIS)},
isbn = {9781467360043},
year = {2013},
title = {Reinforcement learning in swarm-robotics for multi-agent foraging-task domain},
author = {Yogeswaran, M and Ponnambalam, S. G and Kanagaraj, G}
}

@misc{Mohan3,
year = {2011},
title = {A study on foraging behavior of swarm robots using reinforcement learning techniques},
language = {eng},
author = {Mohan, Yogeswaran},
keywords = {Reinforcement Learning ; Q-Learning ; Learning Policy},
url = {https://doi.org/10.4225/03/5893fe61e42bf},
}




@inproceedings{Wei,
abstract = {<p>This research develops and evaluates a new multi-agent adaptive traffic signal control system based on swarm intelligence and the neural-fuzzy actor-critic reinforcement learning (NFACRL) method. The proposed method combines the better attributes of swarm intelligence and the NFACRL method. Two scenarios are used to evaluate the method and the new NFACRL-Swarm method is compared with its NFACRL counterpart. First, the proposed control model is applied to isolated intersection signal adaptive control to evaluate its learning performance. Then, the control system is implemented in signal control coordination in a typical arterial. In the isolated intersection, the proposed hybrid method outperforms its previous counterpart by improving the learning speed and is shown to be insensitive to reward function parameters. In the network, by introducing a coordination scheme inspired by swarm intelligence, the proposed method improves the performance by up to 12% and has a faster learning speed.</p>},
pages = {233--238},
publisher = {IEEE},
booktitle = {2011 IEEE Forum on Integrated and Sustainable Transportation Systems},
isbn = {9781457709906},
year = {2011},
title = {A multi-agent adaptive traffic signal control system using swarm intelligence and neuro-fuzzy reinforcement learning},
language = {eng},
author = {Wei Lu and Yunlong Zhang and Yuanchang Xie},
keywords = {Delay ; Particle Swarm Optimization ; Learning ; Training ; Vehicles ; Adaptation Models ; Optimization},
}


@article{HoangNhat-Duc2018Asim,
issn = {01770667},
abstract = {Determining the shear strength of soil is an important task in the design phase of construction project. This study puts forward an artificial intelligence (AI) solution to estimate this parameter of soil. The proposed approach is a hybrid AI model that integrates the least squares support vector machine (LSSVM) and the cuckoo search optimization (CSO). A dataset of 332 soil samples collected from the Trung Luong National Expressway Project in Viet Nam have been used for constructing and validating the AI model. The sample depth, sand percentage, loam percentage, clay percentage, moisture content, wet density of soil, specific gravity, liquid limit, plastic limit, plastic index, and liquid index are used as input variables to predict the output variable of shear strength. In the hybrid AI framework, LSSVM is employed to generalize the functional mapping that estimates the shear strength from the information provided by the aforementioned input variables. Since the model establishment of LSSVM requires a proper setting of the regularization and the kernel function parameters, the CSO algorithm is utilized to automatically determine these parameters. Experimental results show that the prediction accuracy of the hybrid method of LSSVM and CSO (RMSE = 0.082, MAPE = 14.841, and R2 = 0.885) is better than those of the benchmark approaches including the standard LSSVM, the artificial neural network, and the regression tree. Therefore, the proposed method is a promising alternative for assisting construction engineers in the task of soil shear strength estimation.},
journal = {Engineering with Computers},
pages = {1--11},
publisher = {Springer Science & Business Media},
year = {2018},
title = {A swarm intelligence-based machine learning approach for predicting soil shear strength for road construction: a case study at Trung Luong National Expressway Project (Vietnam)},
language = {eng},
address = {Heidelberg},
author = {Hoang, Nhat-Duc},
keywords = {Vietnam ; Regularization ; Soil Strength ; Swarm Intelligence ; Soil Moisture ; Parameter Estimation ; Shear Strength ; Support Vector Machines ; Specific Gravity ; Artificial Neural Networks ; Neural Networks ; Road Construction ; Mathematical Models ; Regression Analysis ; Moisture Content ; Artificial Intelligence ; Machine Learning ; Predictions ; Density ; Kernel Functions ; Shear Strength ; Plastic Limit ; Soil ; Shear Strength ; Expressway ; Hybrid Artificial Intelligence ; Optimization ; Data-Driven Method},
url = {http://search.proquest.com/docview/2104459705/},
}

@article{Kapoor,
abstract = {Reinforcement Learning (RL) is a learning paradigm concerned with learning to control a system so as to maximize an objective over the long term. This approach to learning has received immense interest in recent times and success manifests itself in the form of human-level performance on games like \textit{Go}. While RL is emerging as a practical component in real-life systems, most successes have been in Single Agent domains. This report will instead specifically focus on challenges that are unique to Multi-Agent Systems interacting in mixed cooperative and competitive environments. The report concludes with advances in the paradigm of training Multi-Agent Systems called \textit{Decentralized Actor, Centralized Critic}, based on an extension of MDPs called \textit{Decentralized Partially Observable MDP}s, which has seen a renewed interest lately.},
year = {2018},
title = {Multi-Agent Reinforcement Learning: A Report on Challenges and Approaches},
author = {Kapoor, Sanyam},
keywords = {Computer Science - Artificial Intelligence ; Computer Science - Machine Learning ; Statistics - Machine Learning},
}


@article{Azad,
issn = {0946-7076},
abstract = {To maintain the integrity, availability, reliability of the data and services available on web requires a strong network security framework, in such consequence IDS based on data mining are the best solution. In this paper we proposed an intrusion detection system which is based on the fuzzy min max neural network and the particle swarm optimization. The proposed system is tested with the help of preprocessed KDD CUP data set. Classification accuracy and classification error are taken as a performance evaluation parameter to test the effectiveness of the system. The proposed system is compared with the some of the well-known methods, the results shows that the proposed system performed well as compared to the other systems.},
journal = {Microsystem Technologies},
pages = {907--918},
volume = {23},
publisher = {Springer Berlin Heidelberg},
number = {4},
year = {2017},
title = {Fuzzy min–max neural network and particle swarm optimization based intrusion detection system},
language = {eng},
address = {Berlin/Heidelberg},
author = {Azad, Chandrashekhar and Jha, Vijay},
keywords = {Artificial Neural Networks ; Data Mining ; Detection Equipment ; Computer Science ; Network Security Software ; Optimization Theory;},
}


@article{AbasAhmedR.2012Ulom,
issn = {1110-8665},
abstract = {In this paper, a new algorithm is presented for unsupervised learning of finite mixture models (FMMs) using data set with missing values. This algorithm overcomes the local optima problem of the Expectation-Maximization (EM) algorithm via integrating the EM algorithm with Particle Swarm Optimization (PSO). In addition, the proposed algorithm overcomes the problem of biased estimation due to overlapping clusters in estimating missing values in the input data set by integrating locally-tuned general regression neural networks with Optimal Completion Strategy (OCS). A comparison study shows the superiority of the proposed algorithm over other algorithms commonly used in the literature in unsupervised learning of FMM parameters that result in minimum mis-classification errors when used in clustering incomplete data set that is generated from overlapping clusters and these clusters are largely different in their sizes.},
journal = {Egyptian Informatics Journal},
pages = {103--109},
volume = {13},
publisher = {Elsevier B.V.},
number = {2},
year = {2012},
title = {Unsupervised learning of mixture models based on swarm intelligence and neural networks with optimal completion using incomplete data},
language = {eng},
author = {Abas, Ahmed R.},
keywords = {Particle Swarm Optimization ; Optimal Completion Strategy ; Expectation–Maximization ; Locally-Tuned General Regression Neural Networks ; Finite Mixture Models ; Unsupervised Learning ; Clustering ; Incomplete Data},
}


@article{ConforthM2010Rlus,
issn = {0952813X},
abstract = {This article proposes a new reinforcement learning method using the swarm intelligence-trained neural network (SWINN) to generate solutions to various real-world problems efficiently. The swarm intelligence algorithm, particle swarm optimisation (PSO), is combined with a training resource allocator (TRA) in SWINN for specific problems. TRA, as a heuristic global search method, controls the allocation of training resources to different candidate topologies of artificial neural networks (ANNs) to expedite the system convergence, while PSO is applied as a local search algorithm to adjust the ANNs connection weights. To evaluate the performance of the SWINN algorithm, two reinforcement learning case studies: the double pole balance (a.k.a. double inverted pendulum) problem and a mobile robot localisation problem are conducted. Extensive simulation results successfully demonstrate that SWINN offers performance that is competitive with modern neuroevolutionary techniques, and is viable for real-world problems. [PUBLICATION ABSTRACT]},
journal = {Journal of Experimental and Theoretical Artificial Intelligence},
volume = {22},
publisher = {Taylor & Francis Ltd.},
number = {3},
year = {2010},
title = {Reinforcement learning using swarm intelligence-trained neural networks},
language = {eng},
address = {Abingdon},
author = {Conforth, M and Meng, Y},
keywords = {Neural Networks ; Algorithms ; Heuristic ; Robots ; Systems Integration ; Simulation ; Artificial Intelligence},
url = {http://search.proquest.com/docview/746770694/},
}


@article{LiuHang2018ARLR,
issn = {2169-3536},
abstract = {<p>In recent years, robotic systems combined with cloud computing capability have become an emerging topic of discussion in academic fields. The concept of cloud robotics allows the system to offload computing-intensive tasks from the robots to the cloud. An appropriate resource allocation scheme is necessary for the cloud computing service platform to efficiently allocate its computing resources, when the robots send requests asking for computing service. This paper proposes a resource allocation scheme based on reinforcement learning (RL), which can make the cloud to decide whether a request should be accepted and how many resources are supposed to be allocated. The scheme realizes an autonomous management of computing resources through online learning, reduces human participation in scheme planning, and improves the overall utility of the system in the long run. Numerical results demonstrate that the proposed RL-based computing resource allocation scheme has better performances than the greedy allocation scheme.</p>},
journal = {IEEE Access},
pages = {17215--17222},
volume = {6},
publisher = {IEEE},
year = {2018},
title = {A Reinforcement Learning-Based Resource Allocation Scheme for Cloud Robotics},
language = {eng},
author = {Liu, Hang and Liu, Shiwen and Zheng, Kan},
keywords = {Cloud Computing ; Task Analysis ; Resource Management ; Robot Sensing Systems ; Information Processing ; Wireless Communication ; Cloud Robotics ; Reinforcement Learning ; Resource Allocation ; Engineering},
}


@article{KawatoMitsuo2007Erlc,
issn = {0959-4388},
abstract = {Reinforcement learning algorithms have provided some of the most influential computational theories for behavioral learning that depends on reward and penalty. After briefly reviewing supporting experimental data, this paper tackles three difficult theoretical issues that remain to be explored. First, plain reinforcement learning is much too slow to be considered a plausible brain model. Second, although the temporal-difference error has an important role both in theory and in experiments, how to compute it remains an enigma. Third, function of all brain areas, including the cerebral cortex, cerebellum, brainstem and basal ganglia, seems to necessitate a new computational framework. Computational studies that emphasize meta-parameters, hierarchy, modularity and supervised learning to resolve these issues are reviewed here, together with the related experimental data.},
journal = {Current Opinion in Neurobiology},
pages = {205--212},
volume = {17},
publisher = {Elsevier Ltd},
number = {2},
year = {2007},
title = {Efficient reinforcement learning: computational theories, neuroscience and robotics},
language = {eng},
author = {Kawato, Mitsuo and Samejima, Kazuyuki},
}



@article{PetarKormushev2013RLiR,
issn = {2218-6581},
abstract = {<p>In robotics, the ultimate goal of reinforcement learning is to endow robots with the ability to learn, improve, adapt and reproduce tasks with dynamically changing constraints based on exploration and autonomous learning. We give a summary of the state-of-the-art of reinforcement learning in the context of robotics, in terms of both algorithms and policy representations. Numerous challenges faced by the policy representation in robotics are identified. Three recent examples for the application of reinforcement learning to real-world robots are described: a pancake flipping task, a bipedal walking energy minimization task and an archery-based aiming task. In all examples, a state-of-the-art expectation-maximization-based reinforcement learning is used, and different policy representations are proposed and evaluated for each task. The proposed policy representations offer viable solutions to six rarely-addressed challenges in policy representations: correlations, adaptability, multi-resolution, globality, multi-dimensionality and convergence. Both the successes and the practical difficulties encountered in these examples are discussed. Based on insights from these particular cases, conclusions are drawn about the state-of-the-art and the future perspective directions for reinforcement learning in robotics.</p>},
journal = {Robotics},
pages = {122--148},
volume = {2},
publisher = {MDPI AG},
number = {3},
year = {2013},
title = {Reinforcement Learning in Robotics: Applications and Real-World Challenges},
language = {eng},
author = {Petar Kormushev and Sylvain Calinon and Darwin G. Caldwell},
keywords = {Reinforcement Learning ; Robotics ; Learning and Adaptive Systems ; Engineering},
url = {https://doaj.org/article/c2d45bea33ee4eb5b6a034ebec1b8ddb},
}


@article{KoberJens2013Rlir,
issn = {0278-3649},
abstract = {<p> Reinforcement learning offers to robotics a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors. Conversely, the challenges of robotic problems provide both inspiration, impact, and validation for developments in reinforcement learning. The relationship between disciplines has sufficient promise to be likened to that between physics and mathematics. In this article, we attempt to strengthen the links between the two research communities by providing a survey of work in reinforcement learning for behavior generation in robots. We highlight both key challenges in robot reinforcement learning as well as notable successes. We discuss how contributions tamed the complexity of the domain and study the role of algorithms, representations, and prior knowledge in achieving these successes. As a result, a particular focus of our paper lies on the choice between model-based and model-free as well as between value-function-based and policy-search methods. By analyzing a simple problem in some detail we demonstrate how reinforcement learning approaches may be profitably applied, and we note throughout open questions and the tremendous potential for future research. </p>},
journal = {The International Journal of Robotics Research},
pages = {1238--1274},
volume = {32},
publisher = {SAGE Publications},
number = {11},
year = {2013},
title = {Reinforcement learning in robotics: A survey},
language = {eng},
address = {London, England},
author = {Kober, Jens and Bagnell, J. Andrew and Peters, Jan},
keywords = {Reinforcement Learning ; Learning Control ; Robot ; Survey ; Engineering},
}



@article{KuremotoTakashi2009Asba,
issn = {1756-378X},
abstract = {<p> Purpose - The purpose of this paper is to present a neuro-fuzzy system with a reinforcement learning algorithm (RL) for adaptive swarm behaviors acquisition. The basic idea is that each individual (agent) has the same internal model and the same learning procedure, and the adaptive behaviors are acquired only by the reward or punishment from the environment. The formation of the swarm is also designed by RL, e.g. temporal difference (TD)-error learning algorithm, and it may bring out a faster exploration procedure comparing with the case of individual learning.Design methodology approach - The internal model of each individual composes a part of input states classification by a fuzzy net, and a part of optimal behavior learning network which adopting a kind of RL methodology named actor-critic method. The membership functions and fuzzy rules in the fuzzy net are adaptively formed online by the change of environment states observed in the trials of agent's behaviors. The weights of connections between the fuzzy net and the action-value functions of actor which provides a stochastic policy of action selection, and critic which provides an evaluation to state transmission, are modified by TD-error.Findings - Simulation experiments of the proposed system with several goal-directed navigation problems are accomplished and the results show that swarms are successfully formed and optimized routes are found by swarm learning faster than the case of individual learning.Originality value - Two techniques, i.e. fuzzy identification system and RL algorithm, are fused into an internal model of the individuals for swarm formation and adaptive behavior acquisition. The proposed model may be applied to multi-agent systems, swarm robotics, metaheuristic optimization, and so on.</p>},
journal = {International Journal of Intelligent Computing and Cybernetics},
pages = {724--744},
volume = {2},
publisher = {Emerald Group Publishing Limited},
number = {4},
year = {2009},
title = {Adaptive swarm behavior acquisition by a neuro-fuzzy system and reinforcement learning algorithm},
language = {eng},
author = {Kuremoto, Takashi and Obayashi, Masanao and Kobayashi, Kunikazu},
keywords = {Robotics ; Programming and Algorithm Theory ; Behaviour ; Systems Theory ; Computer Science},
}


